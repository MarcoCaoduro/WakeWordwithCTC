{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b5615c9",
   "metadata": {},
   "source": [
    "**Description**\n",
    "\n",
    "Implement CTC as this paper describes. Your implementation should support both forward and \n",
    "backward propagation operations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9180e10e",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e32639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchaudio\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import editdistance\n",
    "\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b852c1",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "58432078",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TIMITDataset(Dataset):\n",
    "    def __init__(self, root_dir, subset='TRAIN', transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Root directory of the TIMIT dataset.\n",
    "            subset (str): 'TRAIN' or 'TEST'.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = os.path.join(root_dir, subset)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Collect all file paths\n",
    "        self.items = []\n",
    "        for root, _, files in os.walk(self.root_dir):\n",
    "            for file in files:\n",
    "                if file.endswith(\".WAV\"):  # case-insensitive check\n",
    "                    wav_path = os.path.join(root, file)\n",
    "                    \n",
    "                    # Expected parallel paths\n",
    "                    phn_path = wav_path.replace(\".WAV\", \".PHN\")\n",
    "                    txt_path = wav_path.replace(\".WAV\", \".TXT\")\n",
    "                    \n",
    "                    self.items.append((wav_path, phn_path, txt_path))\n",
    "                   \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        wav_path, phn_path, txt_path = self.items[idx]\n",
    "\n",
    "        # === Load audio using soundfile ===\n",
    "        try:\n",
    "            waveform, sample_rate = sf.read(wav_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {wav_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "        # === Preprocess: Frame, MFCC, Log-Energy, Delta Coefficients ===\n",
    "        features = self.preprocess(waveform, sample_rate)\n",
    "\n",
    "        # === Load phoneme labels ===\n",
    "        phonemes = []\n",
    "        with open(phn_path, 'r') as f:\n",
    "            for line in f:\n",
    "                start, end, label = line.strip().split()\n",
    "                phonemes.append((int(start), int(end), label))\n",
    "\n",
    "        # === Load text transcription ===\n",
    "        with open(txt_path, 'r') as f:\n",
    "            transcript = f.readline().strip()\n",
    "\n",
    "        # === Create the sample dictionary ===\n",
    "        sample = {\n",
    "            'features': features,            # <--- New: Preprocessed Features\n",
    "            'phonemes': phonemes,\n",
    "            'transcript': transcript,\n",
    "            'wav_path': wav_path\n",
    "        }\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def preprocess(self, waveform, sample_rate):\n",
    "        \"\"\"\n",
    "        Preprocesses the audio:\n",
    "        1. Frame into 10ms windows with 5ms overlap.\n",
    "        2. Extract 12 MFCC coefficients.\n",
    "        3. Compute log-energy.\n",
    "        4. Compute first derivatives (deltas).\n",
    "        5. Normalize.\n",
    "        \"\"\"\n",
    "        # === Frame the signal ===\n",
    "        frame_length = int(0.01 * sample_rate)  # 10 ms\n",
    "        frame_step = int(0.005 * sample_rate)   # 5 ms\n",
    "\n",
    "        # === Compute MFCCs ===\n",
    "        mfcc = torchaudio.transforms.MFCC(\n",
    "            sample_rate=sample_rate,\n",
    "            n_mfcc=12,\n",
    "            melkwargs={'n_fft': 400, 'hop_length': frame_step, 'n_mels': 26}\n",
    "        )(torch.tensor(waveform, dtype=torch.float32).unsqueeze(0))\n",
    "\n",
    "        # === Compute log-energy ===\n",
    "        log_energy = torch.log(torch.clamp(mfcc.pow(2).sum(dim=1), min=1e-10)).unsqueeze(0)\n",
    "\n",
    "        # === Compute deltas (first derivatives) ===\n",
    "        delta = torchaudio.functional.compute_deltas(torch.cat([mfcc, log_energy], dim=1))\n",
    "\n",
    "        # === Concatenate MFCC + log-energy + delta ===\n",
    "        features = torch.cat([mfcc, log_energy, delta], dim=1)  # Shape: (1, 26, T)\n",
    "\n",
    "        # === Normalize each feature dimension to mean 0 and std 1 ===\n",
    "        mean = features.mean(dim=2, keepdim=True)\n",
    "        std = features.std(dim=2, keepdim=True)\n",
    "        features = (features - mean) / (std + 1e-10)\n",
    "\n",
    "        return features.squeeze(0).transpose(0, 1)  # Final shape: (T, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0460426b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10\n",
      "Feature shape: torch.Size([290, 26])\n",
      "Phonemes: [(0, 1960, 'h#'), (1960, 2170, 'dh'), (2170, 2616, 'ix'), (2616, 3905, 'm'), (3905, 5639, 'iy'), (5639, 6182, 'dx'), (6182, 7400, 'iy'), (7400, 8293, 'ng'), (8293, 9364, 'ih'), (9364, 10160, 'z'), (10160, 10960, 'epi'), (10960, 11198, 'n'), (11198, 13707, 'aw'), (13707, 14400, 'ix'), (14400, 15200, 'dcl'), (15200, 16072, 'jh'), (16072, 18800, 'er'), (18800, 20137, 'n'), (20137, 20490, 'dcl'), (20490, 20887, 'd'), (20887, 23040, 'h#')]\n",
      "Transcript: 0 23143 The meeting is now adjourned.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the dataset\n",
    "train_dataset = TIMITDataset(root_dir='TIMIT_dataset/data', subset='TRAIN/DR1/FCJF0')\n",
    "\n",
    "# Check the number of samples\n",
    "print(f\"Number of samples: {len(train_dataset)}\")\n",
    "\n",
    "# Get the first sample\n",
    "sample = train_dataset[0]\n",
    "print(\"Feature shape:\", sample['features'].shape)  # (T, 26)\n",
    "print(\"Phonemes:\", sample['phonemes'])\n",
    "print(\"Transcript:\", sample['transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9cf16369",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLSTM_CTC(nn.Module):\n",
    "    def __init__(self, input_dim=26, hidden_dim=100, output_dim=62, num_layers=1):\n",
    "        super(BLSTM_CTC, self).__init__()\n",
    "        \n",
    "        # Bidirectional LSTM\n",
    "        self.blstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Fully connected layer maps 2*hidden_dim (for bidirection) to output_dim\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "        # Activation function\n",
    "        self.log_softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the BLSTM-CTC network.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of shape (batch_size, time_steps, input_dim)\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Log-softmax probabilities of shape (batch_size, time_steps, output_dim) \n",
    "        \"\"\"\n",
    "        # BLSTM forward\n",
    "        x, _ = self.blstm(x)  # x shape: (batch, time_steps, hidden_dim * 2)\n",
    "\n",
    "        # Fully connected to output layer\n",
    "        x = self.fc(x)  # shape: (batch, time_steps, output_dim)\n",
    "\n",
    "        # Apply log softmax for CTC Loss compatibility\n",
    "        x = self.log_softmax(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5be202a",
   "metadata": {},
   "source": [
    "## Computing $p(l | x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d7246f",
   "metadata": {},
   "source": [
    "### Forward variables\n",
    "\n",
    "$$ \\alpha_t(s) := \\sum_{\\pi \\in L'^T \\text{ s.t. } \\mathcal{B}(\\pi_{1:t} = l_{1:s})} \\ \\prod_{t' = 1}^t \\ y_{\\pi_{t'}}^{t'}$$\n",
    "\n",
    "The forward variable $\\alpha_t(s)$ represents the probability of correctly aligning the prefix of the modified label sequence $l'$ (up to position $s$) with the input sequence (up to time step $t$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5b3d50",
   "metadata": {},
   "source": [
    "#### Initialization for Dynamic Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a97933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_forward_values(T, target_sequence, probs):\n",
    "    \"\"\"\n",
    "    Compute the forward values for the CTC loss using dynamic programming.\n",
    "\n",
    "    Args:\n",
    "        T (int): The number of time steps in the input sequence.\n",
    "        target_sequence (list): The target sequence of labels.\n",
    "        probs (np.ndarray): probs[t, s] is the probability of the t-th time step being the s-th label.\n",
    "\n",
    "    Returns:\n",
    "        alpha: The forward values of shape (T, len(target_sequence)).\n",
    "        C: The vector used to normalize the values of alpha\n",
    "    \"\"\"\n",
    "\n",
    "    len_target = len(target_sequence)\n",
    "\n",
    "    # Initialize alpha and C\n",
    "    alpha = np.zeros((T, len_target))\n",
    "    C = np.zeros(T)\n",
    "\n",
    "    # Base cases\n",
    "    alpha[0,0] = probs[0,0] # label 0 is blank\n",
    "    alpha[0,1] = probs[0,target_sequence[0]]\n",
    "\n",
    "    # Recursion\n",
    "    for t in range(1, T):\n",
    "        for s in range(len_target): \n",
    "            alpha[t,s] += alpha[t-1, s]\n",
    "            if s >= 1:\n",
    "                alpha[t,s] += alpha[t-1, s-1]\n",
    "            if s >= 2 and target_sequence[s] != target_sequence[s-2]:\n",
    "                alpha[t,s] += alpha[t-1, s-2]\n",
    "            alpha[t,s] *= probs[t, target_sequence[s]]\n",
    "            C[t] += alpha[t,s]\n",
    "        \n",
    "        # Rescale row\n",
    "        if C[t] != 0:\n",
    "            alpha[t,:] /= C[t]\n",
    "\n",
    "    return alpha, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98889557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_backward_values(T, target_sequence, probs):\n",
    "    \"\"\"\n",
    "    Compute the backward values for the CTC loss using dynamic programming.\n",
    "\n",
    "    Args:\n",
    "        T (int): The number of time steps in the input sequence.\n",
    "        target_sequence (list): The target sequence of labels.\n",
    "        probs (np.ndarray): probs[t, s] is the probability of the t-th time step being the s-th label.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The backward values of shape (T, len(target_sequence)).\n",
    "    \"\"\"\n",
    "\n",
    "    len_target = len(target_sequence)\n",
    "\n",
    "    # Initialize beta matrix\n",
    "    beta = np.zeros((T, len_target))\n",
    "    D = np.zeros(T)\n",
    "\n",
    "    # Base cases\n",
    "    beta[T,len_target] = probs[T,0] # label 0 is blank\n",
    "    beta[T,len_target-1] = probs[0,target_sequence[len_target]]\n",
    "\n",
    "    # Recursion\n",
    "    for t in range(T-1, -1, -1):\n",
    "        for s in range(len_target -1, -1, -1): \n",
    "            beta[t,s] += beta[t+1, s]\n",
    "            if s <= len_target - 2:\n",
    "                beta[t,s] += beta[t+1, s+1]\n",
    "            if s <= len_target - 3 and target_sequence[s] != target_sequence[s+2]:\n",
    "                beta[t,s] += beta[t+1, s+2]\n",
    "            beta[t,s] *= probs[t, target_sequence[s]]\n",
    "            D[t] += beta[t,s]\n",
    "\n",
    "        # Rescale row\n",
    "        if D[t] != 0:\n",
    "            beta[t,:] /= D[t]\n",
    "\n",
    "    return beta, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc2ab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_probability(alpha):\n",
    "    \"\"\"\n",
    "    Compute the total path probability from the forward variables (alpha).\n",
    "\n",
    "    Args:\n",
    "        alpha (numpy.ndarray or torch.Tensor): Forward variables of shape (T, S)\n",
    "\n",
    "    Returns:\n",
    "        float: Total path probability P(y|x)\n",
    "    \"\"\"\n",
    "    _, S = alpha.shape  # Get the number of time steps and states\n",
    "\n",
    "    # Sum of probabilities from the last time step (T-1) at the final two states (S-1 and S-2)\n",
    "    total_prob = alpha[-1, S - 1] + alpha[-1, S - 2]\n",
    "    return total_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc62199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab(sequence, k):\n",
    "    \"\"\"\n",
    "    Returns the set of indices of the sequence where the value is equal to k.\n",
    "\n",
    "    Args:\n",
    "        sequence (list): The input sequence of labels.\n",
    "        k (int): The value to search for in the sequence.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of indices where the value is equal to k.\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for i, value in enumerate(sequence):\n",
    "        if value == k:\n",
    "            indices.append(i)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e194e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_loss_gradiend(probs, target_sequence, alpha, C, beta, D, K):\n",
    "    \"\"\"\n",
    "    Compute the gradient of the CTC loss with respect to the input probabilities.\n",
    "\n",
    "    Args:\n",
    "        probs (np.ndarray): The input probabilities of shape (T, S).\n",
    "        target_sequence (list): The target sequence of labels.\n",
    "        alpha (np.ndarray): The forward variables of shape (T, S).\n",
    "        C (np.ndarray): The normalization vector of shape (T,).\n",
    "        beta (np.ndarray): The backward variables of shape (T, S).\n",
    "        D (np.ndarray): The normalization vector of shape (T,).\n",
    "        K (int): The number of classes.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The gradient of the CTC loss with respect to the input probabilities.\n",
    "    \"\"\"\n",
    "    T, S = probs.shape  # Get the number of time steps and states\n",
    "\n",
    "    # Initialize Q vector: Q[t] = D[t] * (D[t+1]/C[t+1]) * (D[t+2]/C[t+2]) * ... * (D[T-1]/C[T-1]\n",
    "    Q = np.zeros(T)\n",
    "\n",
    "    for t in range(T):\n",
    "        Q[t] = D[t]\n",
    "        for tp in range(t+1, T):\n",
    "            Q[t] *= D[tp]/C[tp]\n",
    "\n",
    "    # Initialize gradient matrix\n",
    "    grad = np.zeros((T, S))\n",
    "\n",
    "    for t in range(T):\n",
    "        for k in range(K):\n",
    "            grad[t,k] = probs[t,k] - Q[t]/probs[t,k] * sum([alpha[t,s] * beta[t,s] for s in lab(target_sequence, k)])\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ddbd57",
   "metadata": {},
   "source": [
    "### Final result, putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141325e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, optimizer, and learning rate\n",
    "model = BLSTM_CTC(input_dim=26, hidden_dim=100, output_dim=62)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "print_every = 1\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (input, target_sequence, input_length) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        probs = model(input)\n",
    "\n",
    "        # Compute forward & backward variables\n",
    "        alpha, C = compute_forward_values(input_length, target_sequence, probs)\n",
    "        beta, D  = compute_backward_values(input_length, target_sequence, probs)\n",
    "\n",
    "        # Compute total probability and gradients\n",
    "        total_prob = compute_total_probability(alpha)\n",
    "        ctc_grads = ctc_loss_gradiend(probs, target_sequence, alpha, C, beta, D, probs.size(2))\n",
    "\n",
    "        # Backpropagation\n",
    "        probs.backward(gradient=torch.tensor(ctc_grads, dtype=torch.float32))\n",
    "        \n",
    "        # === Update parameters immediately (Online Update) ===\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()  # Clear gradients right after the update\n",
    "\n",
    "        # === Logging ===\n",
    "        if (batch_idx + 1) % print_every == 0:\n",
    "            print(f\"Batch {batch_idx + 1} - CTC Loss: {-torch.log(total_prob).item()}\")\n",
    "\n",
    "    print(f\"Finished epoch {epoch + 1}\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39570f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Initialize the model, optimizer, and data loader\n",
    "model = ...  # Your model initialization here\n",
    "optimizer = ...  # Your optimizer initialization here\n",
    "train_loader = ...  # Your data loader here\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = ...  # Number of epochs\n",
    "print_every = ...  # Print frequency\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (input, target_sequence) in enumerate(train_loader):\n",
    "\n",
    "        # NOTE:\n",
    "        # target_sequence needs to be a list of integers representing the target labels,\n",
    "        # some preprocessing may be needed to convert it to the required format.\n",
    "    \n",
    "        # Forward pass\n",
    "        probs = model(input)\n",
    "\n",
    "        # Compute forward & backward variables\n",
    "        alpha, C = compute_forward_values(probs, target_sequence)\n",
    "        beta, D  = compute_backward_values(probs, target_sequence)\n",
    "\n",
    "        # Compute total probability and gradients\n",
    "        total_prob = compute_total_probability(alpha)\n",
    "        ctc_grads = ctc_loss_gradient(probs, target_sequence, alpha, C, beta, D, probs.size(2))\n",
    "\n",
    "        # Backpropagation\n",
    "        probs.backward(gradient=torch.tensor(ctc_grads, dtype=torch.float32))\n",
    "        \n",
    "        # === Update parameters immediately (Online Update) ===\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()  # Clear gradients right after the update\n",
    "\n",
    "        # === Logging ===\n",
    "        if (batch_idx + 1) % print_every == 0:\n",
    "            print(f\"Batch {batch_idx + 1} - CTC Loss: {-torch.log(total_prob).item()}\")\n",
    "\n",
    "    print(f\"Finished epoch {epoch + 1}\")\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
